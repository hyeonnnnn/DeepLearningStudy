{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f04dca38-1ab0-4317-b742-d91dec523e4a",
   "metadata": {},
   "source": [
    "## **a_tensor_initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcb0bb85-618d-4db4-8d0e-fdea22020ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ad71756-0134-45a6-88a1-204aab27fc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# torch.Tensor class\n",
    "t1 = torch.Tensor([1, 2, 3], device='cpu') # [1, 2, 3]를 사용해서 새로운 텐서 생성\n",
    "print(t1.dtype) # torch.Tensor()는 기본적으로 float32 타입 사용\n",
    "print(t1.device) # 텐서가 cpu에 할당\n",
    "print(t1.requires_grad) # 그라디언트 추적을 하지 X\n",
    "print(t1.size()) # 텐서의 크기\n",
    "print(t1.shape) # 텐서의 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a5ef506-4384-474b-803d-a04504de3a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n",
      "cpu\n",
      "False\n",
      "torch.Size([3])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.tensor([1, 2, 3], device='cpu')\n",
    "print(t2.dtype)\n",
    "print(t2.device)\n",
    "print(t2.requires_grad)\n",
    "print(t2.size())\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00d94777-3279-4e19-8cf1-b31bf9bc8c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) 0\n",
      "torch.Size([1]) 1\n",
      "torch.Size([5]) 1\n",
      "torch.Size([5, 1]) 2\n",
      "torch.Size([3, 2]) 2\n",
      "torch.Size([3, 2, 1]) 3\n"
     ]
    }
   ],
   "source": [
    "a1 = torch.tensor(1) # 0차원\n",
    "print(a1.shape, a1.ndim)\n",
    "\n",
    "a2 = torch.tensor([1]) # 1차원\n",
    "print(a2.shape, a2.ndim)\n",
    "\n",
    "a3 = torch.tensor([1, 2, 3, 4, 5]) # 1차원\n",
    "print(a3.shape, a3.ndim)\n",
    "\n",
    "a4 = torch.tensor([[1], [2], [3], [4], [5]]) # 2차원\n",
    "print(a4.shape, a4.ndim)\n",
    "\n",
    "a5 = torch.tensor([ # 2차원\n",
    "    [1, 2],\n",
    "    [3, 4],\n",
    "    [5, 6]\n",
    "])\n",
    "print(a5.shape, a5.ndim)\n",
    "\n",
    "a6 = torch.tensor([ # 3차원\n",
    "    [[1], [2]],\n",
    "    [[3], [4]],\n",
    "    [[5], [6]]\n",
    "])\n",
    "print(a6.shape, a6.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52aebda2-886a-4839-9157-996bbceea406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 2, 1]) 4\n",
      "torch.Size([3, 1, 2, 3]) 4\n",
      "torch.Size([3, 1, 2, 3, 1]) 5\n",
      "torch.Size([4, 5]) 2\n",
      "torch.Size([4, 1, 5]) 3\n"
     ]
    }
   ],
   "source": [
    "a7 = torch.tensor([ # 4차원\n",
    "    [[[1], [2]]],\n",
    "    [[[3], [4]]],\n",
    "    [[[5], [6]]]\n",
    "])\n",
    "print(a7.shape, a7.ndim)\n",
    "\n",
    "a8 = torch.tensor([ # 4차원\n",
    "    [[[1, 2, 3], [2, 3, 4]]],\n",
    "    [[[3, 1, 1], [4, 4, 5]]],\n",
    "    [[[5, 6, 2], [6, 3, 1]]]\n",
    "])\n",
    "print(a8.shape, a8.ndim)\n",
    "\n",
    "\n",
    "a9 = torch.tensor([ # 5차원\n",
    "    [[[[1], [2], [3]], [[2], [3], [4]]]],\n",
    "    [[[[3], [1], [1]], [[4], [4], [5]]]],\n",
    "    [[[[5], [6], [2]], [[6], [3], [1]]]]\n",
    "])\n",
    "print(a9.shape, a9.ndim)\n",
    "\n",
    "a10 = torch.tensor([ # 2차원\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [1, 2, 3, 4, 5],\n",
    "])\n",
    "print(a10.shape, a10.ndim)\n",
    "\n",
    "a10 = torch.tensor([ # 3차원\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "    [[1, 2, 3, 4, 5]],\n",
    "])\n",
    "print(a10.shape, a10.ndim)\n",
    "\n",
    "'''\n",
    "a11 = torch.tensor([ # ValueError: expected sequence of length 3 at dim 3 (got 2)\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "    [[[1, 2, 3], [4, 5]]],\n",
    "])\n",
    "'''\n",
    "# 추가 코드\n",
    "# 차원의 크기가 맞아야 함\n",
    "a11 = torch.tensor([ # 4차원\n",
    "    [[[1, 2, 3], [4, 5, 6]]],\n",
    "    [[[1, 2, 3], [4, 5, 6]]],\n",
    "    [[[1, 2, 3], [4, 5, 6]]],\n",
    "    [[[1, 2, 3], [4, 5, 6]]],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db633ff-61c5-4b01-a04b-8d3af09e3140",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "**torch.Tensor()**\n",
    "\n",
    " - 기본적으로 float32 타입으로 텐서를 생성한다.\n",
    " \n",
    "**torch.tensor()**\n",
    "\n",
    " - 입력된 값의 데이터 타입으로 텐서를 생성한다.\n",
    " - ex. [1, 2, 3]는 int64 타입\n",
    "\n",
    "**Rank**\n",
    "\n",
    " - 0차원 텐서: 스칼라\n",
    " - 1차원 텐서 (행, 열): 벡터\n",
    " - 2차원 텐서 (배치, 높이, 너비): 행렬\n",
    " - 3차원 이상의 텐서: 다차원 배열, 이미지 데이터 같은 복잡한 구조에 활용됨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a50f3-4e07-4231-8f07-e81bec1b87c7",
   "metadata": {},
   "source": [
    "<br/><br/> \n",
    "## **b_tensor_initialization_copy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c783841-9627-42a4-8e46-ec7460c94506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 리스트를 텐서로 변환\n",
    "l1 = [1, 2, 3]\n",
    "t1 = torch.Tensor(l1)\n",
    "\n",
    "l2 = [1, 2, 3]\n",
    "t2 = torch.tensor(l2)\n",
    "\n",
    "l3 = [1, 2, 3]\n",
    "t3 = torch.as_tensor(l3)\n",
    "\n",
    "# 리스트의 요소를 바꾼다면?\n",
    "l1[0] = 100\n",
    "l2[0] = 100\n",
    "l3[0] = 100\n",
    "\n",
    "print(t1) # 바뀌지 않은 값 출력\n",
    "print(t2) # 바뀌지 않은 값 출력\n",
    "print(t3) # 바뀐 값 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81862098-0883-4aef-855a-efaceac1a998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "tensor([1, 2, 3], dtype=torch.int32)\n",
      "tensor([100,   2,   3], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Numpy 배열을 텐서로 변환\n",
    "l4 = np.array([1, 2, 3])\n",
    "t4 = torch.Tensor(l4)\n",
    "\n",
    "l5 = np.array([1, 2, 3])\n",
    "t5 = torch.tensor(l5)\n",
    "\n",
    "l6 = np.array([1, 2, 3])\n",
    "t6 = torch.as_tensor(l6)\n",
    "\n",
    "# 배열의 요소를 바꾼다면?\n",
    "l4[0] = 100 \n",
    "l5[0] = 100\n",
    "l6[0] = 100\n",
    "\n",
    "print(t4) # 바뀌지 않은 값 출력\n",
    "print(t5) # 바뀌지 않은 값 출력\n",
    "print(t6) # 바뀐 값 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13d6fca-11d1-40b1-80f0-4e6c5f2a50f2",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "**torch.Tensor()**\n",
    "- 데이터를 복사하여 텐서를 만든다.\n",
    "- float32 dtype (기본값)\n",
    "\n",
    "**torch.tensor()**\n",
    "- 데이터를 복사하여 텐서를 만든다.\n",
    "- 리스트/배열의 dtype을 따른다.\n",
    "\n",
    "**torch.as_tensor()**\n",
    "- 데이터를 복사하지 않고 메모리를 공유한다.\n",
    "- 리스트/배열이 수정되면 텐서도 바뀐다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2538b4fd-5c2e-4f22-826d-dfbe9ae7db4e",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **c_tensor_initialization_constant_values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9ba1705-09a4-4f67-969d-d05683c41c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([1., 1., 1., 1., 1.])\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([0., 0., 0., 0., 0., 0.])\n",
      "tensor([0.0000, 1.8750, 0.0000, 0.0000])\n",
      "tensor([-8.3304e-17,  1.7937e-42,  0.0000e+00,  0.0000e+00])\n",
      "tensor([[1., 0., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones(size=(5,))  # 크기가 (5,)인 1로 채워진 1차원 텐서 생성\n",
    "t1_like = torch.ones_like(input=t1) # t1과 같은 모양에 1로 채워진 텐서 생성\n",
    "print(t1)\n",
    "print(t1_like)\n",
    "\n",
    "t2 = torch.zeros(size=(6,))\n",
    "t2_like = torch.zeros_like(input=t2)\n",
    "print(t2)\n",
    "print(t2_like)\n",
    "\n",
    "t3 = torch.empty(size=(4,))  # 크기가 (4,)인 비어있는 텐서 생성\n",
    "t3_like = torch.empty_like(input=t3) # t3과 같은 모양의 비어있는 텐서 생성\n",
    "print(t3)\n",
    "print(t3_like)\n",
    "\n",
    "t4 = torch.eye(n=3) # 3x3 크기의 단위행렬 생성\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98def85-d76b-412f-8201-e1c07aab4d6e",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "t1 = torch.ones(5)\n",
    "- 크기가 5인 '1'로 채워진 텐서를 생성한다.\n",
    "\n",
    "torch.ones_like(input=t1)\n",
    "- t1와 같은 모양의 '1'로 채워진 텐서를 생성한다.\n",
    "- torch.zeros(n) / torch.zeros_like(input=t1)\n",
    "- torch.empty(n) / torch.empty_like(input=t1)\n",
    "\n",
    "torch.eye(n=3)\n",
    "- 3x3 크기의 단위행렬을 생성한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8c1826-c400-4315-92f0-d642a64d0314",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **d_tensor_initialization_random_values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85fca6c-3171-427e-bd13-ea4fbfe22fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[19, 13]])\n",
      "tensor([[0.6698, 0.5281, 0.7939]])\n",
      "tensor([[ 0.1970, -0.5411, -0.2311]])\n",
      "tensor([[10.4176, 10.6531],\n",
      "        [11.2185,  9.6710],\n",
      "        [ 9.8560, 10.0624]])\n",
      "tensor([0.0000, 2.5000, 5.0000])\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 10이상 20미만의 정수값으로 채워진 1x2 크기의 텐서 생성\n",
    "t1 = torch.randint(low=10, high=20, size=(1, 2))\n",
    "print(t1)\n",
    "\n",
    "# 0과 1 사이의 값으로 채워진 1x3 크기의 텐서 생성\n",
    "t2 = torch.rand(size=(1, 3))\n",
    "print(t2)\n",
    "\n",
    "# 평균이 0이고, 표준편차가 1인 정규분포에서 추출된 1x3 크기의 텐서 생성\n",
    "t3 = torch.randn(size=(1, 3))\n",
    "print(t3)\n",
    "\n",
    "# 평균이 10, 표준편차가 1인 정규분포에서 추출된 3x2 크기의 텐서 생성\n",
    "t4 = torch.normal(mean=10.0, std=1.0, size=(3, 2))\n",
    "print(t4)\n",
    "\n",
    "# 0부터 5까지 모든 데이터를 균등하게 나눈 텐서 생성\n",
    "t5 = torch.linspace(start=0.0, end=5.0, steps=3)\n",
    "print(t5)\n",
    "\n",
    "# 0부터 5미만까지 1씩 증가하는 데이터로 이루어진 텐서 생성\n",
    "t6 = torch.arange(5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f9fbfa0-c9a9-4ae9-b220-fd9437bb9658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "# 시드를 고정하여 동일한 난수 생성\n",
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(random2)\n",
    "\n",
    "print()\n",
    "\n",
    "# 시드를 똑같이 설정하면 동일한 랜덤 텐서 생성\n",
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(random4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797bafd9-d45e-4755-a406-63d33aee11e5",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "**torch.randint()**\n",
    "\n",
    "- 주어진 범위 [low, high) 내의 정수로 구성된 텐서를 생성한다.\n",
    "\n",
    "**torch.rand():**\n",
    "\n",
    "- 0과 1 사이의 실수로 구성된 텐서를 생성한다.\n",
    "\n",
    "**torch.randn():**\n",
    "\n",
    "- 평균이 0, 표준편차가 1인 정규분포에서 값을 추출하여 텐서를 생성한다.\n",
    "\n",
    "**torch.normal():**\n",
    "\n",
    "- 지정된 평균과 표준편차를 가지는 정규분포에서 값을 추출하여 텐서를 생성한다.\n",
    "\n",
    "**torch.linspace():**\n",
    "\n",
    "- 시작점과 끝점 사이를 steps 개수로 균등하게 나눈 값을 포함하는 텐서를 생성한다.\n",
    "\n",
    "**torch.arange()**:\n",
    "\n",
    "- 0부터 시작하여 지정된 끝까지의 값을 1씩 증가시키며 나열한 텐서를 생성한다.\n",
    "\n",
    "**torch.manual_seed()**:\n",
    "\n",
    "- 난수 생성기의 시드를 고정하여 동일한 난수를 재현할 수 있게 한다. 한 번 설정된 시드는 이후의 모든 무작위 값이 동일하게 나오도록 보장한다.\n",
    "- 동일한 시드를 설정하면 항상 같은 결과를 얻을 수 있어 디버깅이나 실험을 반복할 때 유용하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5563c556-4190-4c38-aa56-6fdc24a0071d",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **e_tensor_type_conversion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0a6f534-790f-468b-b66b-901ec0c4d42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int16)\n",
      "tensor([[18.0429,  7.2532, 19.6519],\n",
      "        [10.8626,  2.1505, 19.6913]], dtype=torch.float64)\n",
      "tensor([[1, 1, 1],\n",
      "        [1, 1, 1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones((2, 3))\n",
    "print(a.dtype)\n",
    "\n",
    "b = torch.ones((2, 3), dtype=torch.int16)\n",
    "print(b)\n",
    "\n",
    "c = torch.rand((2, 3), dtype=torch.float64) * 20.\n",
    "print(c)\n",
    "\n",
    "d = b.to(torch.int32) # int16 타입의 텐서 b를 int32 타입으로 변환\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c41225a-673e-4431-ac42-3aa4ced80161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "torch.int16\n"
     ]
    }
   ],
   "source": [
    "double_d = torch.ones(10, 2, dtype=torch.double)\n",
    "short_e = torch.tensor([[1, 2]], dtype=torch.short)\n",
    "\n",
    "double_d = torch.zeros(10, 2).double() # double 타입으로 변환\n",
    "short_e = torch.ones(10, 2).short() # short 타입으로 변환\n",
    "\n",
    "double_d = torch.zeros(10, 2).to(torch.double) # double 타입으로 변환\n",
    "short_e = torch.ones(10, 2).to(dtype=torch.short) # short 타입으로 변환\n",
    "\n",
    "double_d = torch.zeros(10, 2).type(torch.double) # double 타입으로 변환\n",
    "short_e = torch.ones(10, 2). type(dtype=torch.short) # short 타입으로 변환\n",
    "\n",
    "print(double_d.dtype)\n",
    "print(short_e.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "196a9243-d063-4cb8-9f85-5571385490c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n"
     ]
    }
   ],
   "source": [
    "double_f = torch.rand(5, dtype=torch.double)\n",
    "short_g = double_f.to(torch.short)\n",
    "print((double_f * short_g).dtype) # double_f와 short_g를 곱한 텐서의 데이터 타입 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0e73a-3247-430e-aea6-9da978068acf",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "타입을 변환하는 방법\n",
    "\n",
    "- **.double()**\n",
    "- **.to(** torch.double **)**\n",
    "- **.type(** torch.double **)**\n",
    "\n",
    "연산 후 결과 데이터 타입\n",
    "\n",
    "- 텐서 간의 연산 후 데이터 타입은 더 높은 정밀도의 타입이 유지된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196c92ca-eca5-4395-bda0-2b61364c207c",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **f_tensor_operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a99b2a23-a327-4f8e-ad62-7d3830ac2ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n",
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.ones(size=(2, 3))\n",
    "t2 = torch.ones(size=(2, 3))\n",
    "# 덧셈 연산\n",
    "t3 = torch.add(t1, t2)\n",
    "t4 = t1 + t2\n",
    "print(t3)\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f6d614d-6918-42a9-a616-d0c5f65f3816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# 뺄셈 연산\n",
    "t5 = torch.sub(t1, t2)\n",
    "t6 = t1 - t2\n",
    "print(t5)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48756d89-f5ba-41d5-9747-d3489058dd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 곱셈 연산\n",
    "t7 = torch.mul(t1, t2)\n",
    "t8 = t1 * t2\n",
    "print(t7)\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdb97428-7245-44c7-90e1-ae2cbdbc6fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# 나눗셈 연산\n",
    "t9 = torch.div(t1, t2)\n",
    "t10 = t1 / t2\n",
    "print(t9)\n",
    "print(t10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5011a67e-9487-4c17-8f1f-f192aef71560",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "텐서 간의 연산 함수 종류 \n",
    "\n",
    "- **torch.add()**: 두 텐서의 각 요소를 더한다.\n",
    "- **torch.sub()**: 두 텐서의 각 요소를 뺀다.\n",
    "- **torch.mul()**: 두 텐서의 각 요소를 곱한다.\n",
    "- **torch.div()**: 두 텐서의 각 요소를 나눈다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca661374-7d0b-43fd-8adc-847d48fabb28",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **g_tensor_operations_mm**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "930de0b7-8d5e-4210-bb7e-61fcc3e6a9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# torch.dot(): 1차원 벡터 간의 내적 계산\n",
    "t1 = torch.dot(\n",
    "  torch.tensor([2, 3]), torch.tensor([2, 1])\n",
    ")\n",
    "print(t1, t1.size())\n",
    "# 2*2 + 3*1 = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2be0daa3-c46e-4866-8506-38b6b9eea102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.6750, 2.2840],\n",
      "        [0.0956, 1.0294]]) torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# torch.mm(): 2차원 행렬 간의 행렬 곱 계산\n",
    "t2 = torch.randn(2, 3) # (2, 3)\n",
    "t3 = torch.randn(3, 2) # (3, 2)\n",
    "t4 = torch.mm(t2, t3) # (2, 2)\n",
    "print(t4, t4.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc1bf976-f4c6-40ba-9213-a80b3ed84e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# torch.bmm(): 3차원 배치 행렬 간의 곱 계산\n",
    "t5 = torch.randn(10, 3, 4) # (10, 3, 4)\n",
    "t6 = torch.randn(10, 4, 5) # (10, 4, 5)\n",
    "t7 = torch.bmm(t5, t6) # (10, 3, 5)\n",
    "print(t7.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6cf54-4d7e-4245-8201-fcc8be73350a",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "텐서 간의 연산 함수\n",
    "\n",
    "- **torch.dot()**\n",
    "    - 1차원 벡터 간의 내적을 계산한다.\n",
    "    - 결과: 스칼라 값이 반환된다.\n",
    "\n",
    "- **torch.mm()**\n",
    "    - 2차원 텐서 간의 행렬 곱을 계산한다.\n",
    "    - 두 행렬의 행과 열 크기에 따라 행렬이 반한된다.\n",
    "    - ex. (2, 3)과 (3, 2) -> (2, 2)\n",
    "\n",
    "- **torch.bmm()**\n",
    "    - 3차원 배치 행렬 간의 곱을 계산한다.\n",
    "    - 배치 크기와 행렬 곱의 규칙에 따라 행렬이 반환된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee86322-830d-48dc-a565-8e3c71425d22",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **h_tensor_operations_matmul**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46420bd9-ff48-4330-a8ee-ad20ec1ec66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "# vector x vector: dot product\n",
    "t1 = torch.randn(3) # 1차원\n",
    "t2 = torch.randn(3) # 1차원\n",
    "print(torch.matmul(t1, t2).size()) # 내적 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67626166-1ce0-4bbb-85e6-9caea2c4712e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# matrix x vector: broadcasted dot\n",
    "t3 = torch.randn(3, 4) # 2차원\n",
    "t4 = torch.randn(4) # 1차원\n",
    "print(torch.matmul(t3, t4).size()) # 내적 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f315eba-c2af-4010-9451-580a37e9afc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3])\n"
     ]
    }
   ],
   "source": [
    "# batched matrix x vector: broadcasted dot\n",
    "t5 = torch.randn(10, 3, 4) # 3차원\n",
    "t6 = torch.randn(4) # 1차원\n",
    "print(torch.matmul(t5, t6).size()) # 내적 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "000d4c3c-5171-4d07-b2aa-303479f537e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# batched matrix x batched matrix: bmm\n",
    "t7 = torch.randn(10, 3, 4) # 3차원\n",
    "t8 = torch.randn(10, 4, 5) # 3차원\n",
    "print(torch.matmul(t7, t8).size()) # 내적 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9f1b7fc4-92b3-4781-91a5-0eeeee7ddffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 3, 5])\n"
     ]
    }
   ],
   "source": [
    "# batched matrix x matrix: bmm\n",
    "t9 = torch.randn(10, 3, 4) # 3차원\n",
    "t10 = torch.randn(4, 5) # 2차원\n",
    "print(torch.matmul(t9, t10).size())  # 내적 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c02ebb-f979-4a8b-abac-f69c010bf0ae",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "**torch.matmal()** 을 사용하여 다양한 차원의 텐서끼리 곱셈을 할 수 있다.\n",
    "\n",
    "- 벡터 x 벡터: 1차원 벡터 간의 내적을 계산한다.\n",
    "- 행렬 x 벡터: 행렬과 벡터 간의 곱을 계산한다.\n",
    "- 배치된 행렬 x 벡터: 각 배치된 행렬에 벡터를 곱한다.\n",
    "- 배치된 행렬 x 배치된 행렬: 각 배치에 대해 행렬 곱을 계산한다.\n",
    "- 배치된 행렬 x 일반 행렬: 배치된 행렬에 일반 행렬을 곱한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5836914e-28d7-4c74-8810-94ae3e5690dd",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **i_tensor_broadcasting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b807cd2f-ac9d-4746-81a6-3cbc94cb496a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 4., 6.])\n",
      "tensor([[-4, -4],\n",
      "        [-2, -1],\n",
      "        [ 6,  5]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "t2 = 2.0\n",
    "print(t1 * t2) # t1의 각 요소에 t2 스칼라 곱한 값 출력하기\n",
    "# [1.0 * 2.0, 2.0 * 2.0, 3.0 * 2.0]\n",
    "\n",
    "t3 = torch.tensor([[0, 1], [2, 4], [10, 10]])\n",
    "t4 = torch.tensor([4, 5])\n",
    "print(t3 - t4) # t3의 각 행에 t4를 브로드캐스팅하여 빼기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8172d5c2-d713-455b-9f40-4858b54b9fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 4.],\n",
      "        [5., 6.]])\n",
      "tensor([[-1.,  0.],\n",
      "        [ 1.,  2.]])\n",
      "tensor([[2., 4.],\n",
      "        [6., 8.]])\n",
      "tensor([[0.5000, 1.0000],\n",
      "        [1.5000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.tensor([[1., 2.], [3., 4.]])\n",
    "print(t5 + 2.0)\n",
    "print(t5 - 2.0)\n",
    "print(t5 * 2.0)\n",
    "print(t5 / 2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e25b4440-f0ee-4e13-81d5-6f706c5500fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "  return x / 255\n",
    "\n",
    "t6 = torch.randn(3, 28, 28) # (3, 28, 28)\n",
    "print(normalize(t6).size()) # t6의 각 요소를 255로 나누어 정규화한 값 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82aa7c07-b734-4b9b-91a4-76dd9421dae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4, 3],\n",
      "        [3, 4]])\n",
      "tensor([[6, 7],\n",
      "        [2, 5]])\n",
      "tensor([[8, 6],\n",
      "        [5, 3]])\n",
      "tensor([[ 8,  9],\n",
      "        [ 7, 10]])\n"
     ]
    }
   ],
   "source": [
    "# 서로 다른 크기의 텐서에 브로드캐스팅으로 덧셈하기\n",
    "t7 = torch.tensor([[1, 2], [0, 3]]) \n",
    "t8 = torch.tensor([[3, 1]]) \n",
    "t9 = torch.tensor([[5], [2]]) \n",
    "t10 = torch.tensor([7]) \n",
    "print(t7 + t8) \n",
    "print(t7 + t9) \n",
    "print(t8 + t9) \n",
    "print(t7 + t10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "664f4a86-fb59-41fe-9b8b-eeb929bff185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 2])\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([4, 3, 2])\n",
      "torch.Size([5, 3, 4, 1])\n",
      "torch.Size([5, 3, 4, 1])\n",
      "torch.Size([3, 1, 7])\n",
      "torch.Size([3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# 브로드캐스팅은 같지 않은 차원을 자동으로 맞추어 계산함\n",
    "t11 = torch.ones(4, 3, 2)\n",
    "t12 = t11 * torch.rand(3, 2)\n",
    "print(t12.shape)\n",
    "\n",
    "\n",
    "t13 = torch.ones(4, 3, 2)\n",
    "t14 = t13 * torch.rand(3, 1)\n",
    "print(t14.shape)\n",
    "# t14의 세 번째 차원이 2로 확장된다. 1->2\n",
    "# (4, 3, 2)\n",
    "\n",
    "t15 = torch.ones(4, 3, 2)\n",
    "t16 = t15 * torch.rand(1, 2)\n",
    "print(t16.shape)\n",
    "# t16의 첫 번째 차원이 3으로 확장된다. 1->3\n",
    "# (4, 3, 2)\n",
    "\n",
    "t17 = torch.ones(5, 3, 4, 1)\n",
    "t18 = torch.rand(3, 1, 1)\n",
    "print((t17 + t18).size())\n",
    "# t18의 두 번째 차원이 4로 확장된다. 1->4\n",
    "# (5, 3, 4, 1)\n",
    "\n",
    "t19 = torch.empty(5, 1, 4, 1)\n",
    "t20 = torch.empty(3, 1, 1)\n",
    "print((t19 + t20).size())\n",
    "# t19의 첫 번째 차원이 3으로 확장된다. 1->3\n",
    "# (5, 3, 4, 1)\n",
    "\n",
    "t21 = torch.empty(1)\n",
    "t22 = torch.empty(3, 1, 7)\n",
    "print((t21 + t22).size())\n",
    "# t21의 모든 차원이 확장되어 t22와 동일한 크기가 된다.\n",
    "# (3, 1, 7)\n",
    "\n",
    "t23 = torch.ones(3, 3, 3)\n",
    "t24 = torch.ones(3, 1, 3)\n",
    "print((t23 + t24).size())\n",
    "# t24의 두 번째 차원이 3으로 확장된다. 1->3\n",
    "\n",
    "# t25 = torch.empty(5, 2, 4, 1)\n",
    "# t26 = torch.empty(3, 1, 1)\n",
    "# print((t25 + t26).size())\n",
    "# RuntimeError: The size of tensor a (2) must match\n",
    "# the size of tensor b (3) at non-singleton dimension 1\n",
    "\n",
    "# 브로드캐스팅의 규칙\n",
    "# -> 텐서의 각 차원은 같거나 한 차원이 1이어야 한다.\n",
    "# 하지만 t25의 2와 t26의 3은 같지 않으며 어느것도 1이 아니다.\n",
    "# 따라서 이 부분에서 충돌이 생긴다.\n",
    "# 만약 t26이 (1, 1, 1)이라면 충돌이 생기지 않을 것이다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9bc51d8-ce10-4ee6-83a5-8fd93fe09a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 5., 5., 5.])\n",
      "tensor([25., 25., 25., 25.])\n",
      "tensor([  1.,   4.,  27., 256.])\n"
     ]
    }
   ],
   "source": [
    "t27 = torch.ones(4) * 5 # 각 요소에 5 곱하기 \n",
    "print(t27)\n",
    "\n",
    "t28 = torch.pow(t27, 2) # t27의 각 요소에 제곱 계산\n",
    "print(t28)\n",
    "\n",
    "exp = torch.arange(1., 5.) # [ 1.,  2.,  3.,  4.]\n",
    "a = torch.arange(1., 5.) # [ 1.,  2.,  3.,  4.]\n",
    "t29 = torch.pow(a, exp) # a의 각 요소에 exp의 요소를 제곱하여 계산\n",
    "print(t29)\n",
    "# [1^1, 2^2, 3^3, 4^4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29db445-6b7f-491f-ab32-f66da5952980",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "**브로드캐스팅**\n",
    "\n",
    "- PyTorch에서 브로드캐스팅을 자동으로 텐서의 차원을 맞추어서 연산을 할 수 있게 한다.\n",
    "- 뒤에서부터 차원을 맞추어 본다.\n",
    "- 텐서의 각 차원은 같거나 하나가 1이어야 한다.\n",
    "- 만약 하나가 1이면 해당 차원이 다른 텐서의 크기로 확장된다.\n",
    "\n",
    "**지수 연산**\n",
    "\n",
    "- **torch.pow()** 으로 텐서의 각 요소에 지수 연산을 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c73a16-576b-4a12-a1ee-35e0f99ee67a",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **j_tensor_indexing_slicing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00f8c511-b6ca-472f-93fe-d327e37550ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5, 6, 7, 8, 9])\n",
      "tensor([ 1,  6, 11])\n",
      "tensor(7)\n",
      "tensor([ 4,  9, 14])\n",
      "tensor([[ 5,  6,  7,  8,  9],\n",
      "        [10, 11, 12, 13, 14]])\n",
      "tensor([[ 8,  9],\n",
      "        [13, 14]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(\n",
    "  [[0, 1, 2, 3, 4], # 0번째 행\n",
    "   [5, 6, 7, 8, 9], # 1번째 행\n",
    "   [10, 11, 12, 13, 14]] # 2번째 행\n",
    ")\n",
    "\n",
    "print(x[1]) # 1번째 행\n",
    "print(x[:, 1]) # 각 행의 1번째 열\n",
    "print(x[1, 2]) # 1번째 행, 2번째 열\n",
    "print(x[:, -1]) # 각 행의 마지막 열\n",
    "print(x[1:]) # 1번째부터 마지막 행\n",
    "print(x[1:, 3:]) # 1번째부터 마지막 행, 3번째부터 마지막 열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "74f17bc3-53a1-4501-aa2e-0b7ea17cd6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[0., 1., 0.],\n",
      "        [0., 1., 0.],\n",
      "        [0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.zeros((6, 6))\n",
    "y[1:4, 2] = 1 # 1번째부터 4번째 행의 2번째 열을 1로 설정\n",
    "print(y)\n",
    "print(y[1:4, 1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82c28398-3b7f-4a30-b191-207e38d86fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 3, 4, 5]])\n",
      "tensor([[3, 4],\n",
      "        [6, 7]])\n",
      "tensor([[2, 3, 4],\n",
      "        [3, 4, 5],\n",
      "        [6, 7, 8]])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [2, 0, 0, 5],\n",
      "        [5, 0, 0, 8]])\n"
     ]
    }
   ],
   "source": [
    "z = torch.tensor(\n",
    "  [[1, 2, 3, 4],\n",
    "   [2, 3, 4, 5],\n",
    "   [5, 6, 7, 8]]\n",
    ")\n",
    "print(z[:2])\n",
    "print(z[1:, 1:3])\n",
    "print(z[:, 1:])\n",
    "\n",
    "z[1:, 1:3] = 0\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab75ff-e97f-4a02-9f89-7b2bc61d4b31",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "슬라이싱\n",
    "\n",
    "-  텐서의 특정 부분을 쉽게 선택하고 수정할 수 있게 해준다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56deb09-c55a-414a-abb1-bd0940b6ccf9",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **k_tensor_reshaping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef2b2653-9917-444c-81bd-4ba87ca344d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4],\n",
      "        [5, 6]])\n",
      "tensor([[1, 2, 3, 4, 5, 6]])\n",
      "tensor([[0, 1, 2, 3],\n",
      "        [4, 5, 6, 7]])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = t1.view(3, 2) # 텐서의 모양을 (3, 2)로 바꾸기\n",
    "t3 = t1.reshape(1, 6) # 텐서의 모양을 (1, 6)로 바꾸기\n",
    "print(t2)\n",
    "print(t3)\n",
    "\n",
    "t4 = torch.arange(8).view(2, 4)  # 텐서의 모양을 (2, 4)로 바꾸기\n",
    "t5 = torch.arange(6).view(2, 3)  # 텐서의 모양을 (2, 3)로 바꾸기\n",
    "print(t4)\n",
    "print(t5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "166c4adb-4e89-49a6-9b50-f2c8ddf06058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n"
     ]
    }
   ],
   "source": [
    "t6 = torch.tensor([[[1], [2], [3]]]) # ()\n",
    "\n",
    "t7 = t6.squeeze() # 크기가 1인 차원 제거\n",
    "# \n",
    "t8 = t6.squeeze(0) # 첫 번째 차원 제거\n",
    "# \n",
    "print(t7)\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "47e1bf6f-1b45-4953-ad26-b2cc973dc660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1],\n",
      "        [2],\n",
      "        [3]])\n",
      "tensor([[[1, 2, 3]],\n",
      "\n",
      "        [[4, 5, 6]]]) torch.Size([2, 1, 3])\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.tensor([1, 2, 3])\n",
    "\n",
    "t10 = t9.unsqueeze(1) # 첫 번째 위치에 새로운 차원 추가하기\n",
    "print(t10)\n",
    "\n",
    "t11 = torch.tensor(\n",
    "  [[1, 2, 3],\n",
    "   [4, 5, 6]]\n",
    ")\n",
    "t12 = t11.unsqueeze(1) # 첫 번째 위치에 새로운 차원 추가하기\n",
    "print(t12, t12.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3a88d9f-829a-4b00-82cb-bad062c418e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n",
      "tensor([1, 2, 3, 4, 5, 6, 7, 8])\n",
      "tensor([[1, 2, 3, 4],\n",
      "        [5, 6, 7, 8]])\n"
     ]
    }
   ],
   "source": [
    "t13 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t14 = t13.flatten()  # 모든 차원을 평탄화하기 (6,)\n",
    "print(t14)\n",
    "\n",
    "t15 = torch.tensor([[[1, 2],\n",
    "                     [3, 4]],\n",
    "                    [[5, 6],\n",
    "                     [7, 8]]])\n",
    "t16 = torch.flatten(t15) # 모든 차원을 평탄화하기\n",
    "t17 = torch.flatten(t15, start_dim=1) # 첫 번째 차원부터 평탄화하기\n",
    "print(t16)\n",
    "print(t17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4dc2f8c7-ab6d-40b6-8e60-7d7114f76f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 5])\n",
      "torch.Size([5, 2, 3])\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "t18 = torch.randn(2, 3, 5)\n",
    "print(t18.shape)\n",
    "print(torch.permute(t18, (2, 0, 1)).size()) # 차원을 (2, 0, 1) 순서로 재배치하기\n",
    "\n",
    "t19 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "t20 = torch.permute(t19, dims=(0, 1))  # 모양 유지하기\n",
    "t21 = torch.permute(t19, dims=(1, 0))  # 차원 전치하기\n",
    "print(t20)\n",
    "print(t21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf229981-d305-4a16-9d1c-31ceeb9b5b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "t22 = torch.transpose(t19, 0, 1) # 차원 전치하기\n",
    "print(t22)\n",
    "t23 = torch.t(t19) # 2차원 행렬 전치하기\n",
    "print(t23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b31915-46db-4389-bd79-c1f3aab891c5",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "텐서의 모양을 변경하는 연산\n",
    "\n",
    "-  **view()**: 텐서의 모양을 바꾼다. (메모리 레이아웃이 그대로다.)\n",
    "-  **reshape()**: 텐서릐 모양을 바꾼다. (메모리를 새로 할당할 수 있다.)\n",
    "\n",
    "-  **squeeze()**: 차원을 제거한다.\n",
    "-  **unsqueeze()**: 차원을 추가한다.\n",
    "  \n",
    "-  **flatten()**: 차원을 평탄화한다.\n",
    "-  **permute()**: 차원을 재배치한다.\n",
    "-  **transpose()**, **t()**: 텐서를 전치한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac3f79-da55-484c-8b73-7344f3a83464",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **l_tensor_concat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e10ee32a-4c81-417f-a0bc-e4dcdc4121ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 6, 3])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.zeros([2, 1, 3])\n",
    "t2 = torch.zeros([2, 3, 3])\n",
    "t3 = torch.zeros([2, 2, 3])\n",
    "\n",
    "# 3차원 텐서간의 결합\n",
    "t4 = torch.cat([t1, t2, t3], dim=1) # (2, 1+3+2, 3)\n",
    "print(t4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "131f52ac-3a54-41b8-ae3c-4cacaf0de1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "t5 = torch.arange(0, 3)  # [0, 1, 2]\n",
    "t6 = torch.arange(3, 8)  # [3, 4, 5, 6, 7]\n",
    "\n",
    "# 1차원 텐서 간의 결합\n",
    "t7 = torch.cat((t5, t6), dim=0) # 첫 번째 차원에서 이어붙이기\n",
    "# [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "\n",
    "print(t7.shape)\n",
    "print(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88b7a4de-579a-458a-a6a3-53c9abbeeeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11]])\n",
      "torch.Size([2, 6])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8],\n",
      "        [ 3,  4,  5,  9, 10, 11]])\n"
     ]
    }
   ],
   "source": [
    "t8 = torch.arange(0, 6).reshape(2, 3) # (2, 3)\n",
    "t9 = torch.arange(6, 12).reshape(2, 3) # (2, 3)\n",
    "\n",
    "# 2차원 텐서간 병합\n",
    "t10 = torch.cat((t8, t9), dim=0) # 첫 번째 차원에서 결합하기 (2+2, 3)\n",
    "print(t10.size())\n",
    "print(t10)\n",
    "\n",
    "t11 = torch.cat((t8, t9), dim=1) # 두 번째 행에서 결합하기 (2, 3+3)\n",
    "print(t11.size())\n",
    "print(t11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e0262784-3c99-4782-ad47-6d5b024bef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 3])\n",
      "tensor([[ 0,  1,  2],\n",
      "        [ 3,  4,  5],\n",
      "        [ 6,  7,  8],\n",
      "        [ 9, 10, 11],\n",
      "        [12, 13, 14],\n",
      "        [15, 16, 17]])\n",
      "torch.Size([2, 9])\n",
      "tensor([[ 0,  1,  2,  6,  7,  8, 12, 13, 14],\n",
      "        [ 3,  4,  5,  9, 10, 11, 15, 16, 17]])\n"
     ]
    }
   ],
   "source": [
    "t12 = torch.arange(0, 6).reshape(2, 3) # (2, 3)\n",
    "t13 = torch.arange(6, 12).reshape(2, 3) # (2, 3)\n",
    "t14 = torch.arange(12, 18).reshape(2, 3) # (2, 3)\n",
    "\n",
    "\n",
    "t15 = torch.cat((t12, t13, t14), dim=0) # 첫 번째 차원에서 결합하기 (2+2+2, 3)\n",
    "print(t15.size()) \n",
    "print(t15)\n",
    "\n",
    "t16 = torch.cat((t12, t13, t14), dim=1) # 두 번째 차원에서 결합하기 (2, 3+3+3)\n",
    "print(t16.size())\n",
    "print(t16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26740489-e8c6-44bf-9ace-a17167dcfef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5]],\n",
      "\n",
      "        [[ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 4, 3])\n",
      "tensor([[[ 0,  1,  2],\n",
      "         [ 3,  4,  5],\n",
      "         [ 6,  7,  8],\n",
      "         [ 9, 10, 11]]])\n",
      "torch.Size([1, 2, 6])\n",
      "tensor([[[ 0,  1,  2,  6,  7,  8],\n",
      "         [ 3,  4,  5,  9, 10, 11]]])\n"
     ]
    }
   ],
   "source": [
    "t17 = torch.arange(0, 6).reshape(1, 2, 3)  # (1, 2, 3)\n",
    "t18 = torch.arange(6, 12).reshape(1, 2, 3)  # (1, 2, 3)\n",
    "\n",
    "# 3차원 텐서 간의 결합\n",
    "t19 = torch.cat((t17, t18), dim=0) # (1+1, 2, 3)\n",
    "print(t19.size())\n",
    "print(t19)\n",
    "\n",
    "t20 = torch.cat((t17, t18), dim=1) # (1, 2+2, 3)\n",
    "print(t20.size())\n",
    "print(t20)\n",
    "\n",
    "t21 = torch.cat((t17, t18), dim=2) # (1, 2, 3+3)\n",
    "print(t21.size())\n",
    "print(t21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201c90eb-133c-4e62-b698-6a136c4760c8",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "텐서를 결합하는 방식\n",
    "\n",
    "- **torch.cat()**\n",
    "  \n",
    "     - 지정된 차원에서 텐서를 결합한다.\n",
    "     - 결합하려는 차원을 제외한 다른 차원의 크기는 동일해야 한다.\n",
    "     - dim=0: 첫 번째 차원, dim=1: 두 번째 차원, dim=2: 세 번째 차원"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cecfac-4780-49bc-abe2-b0e2fff5fdaa",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **m_tensor_stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa6d6770-3995-4827-b4a1-87f1b6f3b7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3]) True\n",
      "torch.Size([2, 2, 3]) True\n",
      "torch.Size([2, 3, 2]) True\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "t2 = torch.tensor([[7, 8, 9], [10, 11, 12]])\n",
    "\n",
    "t3 = torch.stack([t1, t2], dim=0) # 첫 번째 차원을 따라 텐서 쌓기\n",
    "t4 = torch.cat([t1.unsqueeze(dim=0), t2.unsqueeze(dim=0)], dim=0) # 각 텐서에 첫 번째 차원을 추가하고 결합하기\n",
    "print(t3.shape, t3.equal(t4)) # 두 결과가 같은지 확인하기\n",
    "\n",
    "t5 = torch.stack([t1, t2], dim=1) # 두 번째 차원을 따라 텐서 쌓기\n",
    "t6 = torch.cat([t1.unsqueeze(dim=1), t2.unsqueeze(dim=1)], dim=1) # 각 텐서에 두 번째 차원을 추가하고 결합하기\n",
    "print(t5.shape, t5.equal(t6)) # 두 결과가 같은지 확인하기\n",
    "\n",
    "t7 = torch.stack([t1, t2], dim=2) # 세 번째 차원을 따라 텐서 쌓기\n",
    "t8 = torch.cat([t1.unsqueeze(dim=2), t2.unsqueeze(dim=2)], dim=2) # 각 텐서에 세 번째 차원을 추가하고 결합하기\n",
    "print(t7.shape, t7.equal(t8)) # 두 결과가 같은지 확인하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "32f8a96d-c545-40b3-b13d-a9195a205cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) torch.Size([3])\n",
      "torch.Size([2, 3])\n",
      "tensor([[0, 1, 2],\n",
      "        [3, 4, 5]])\n",
      "True\n",
      "torch.Size([3, 2])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "t9 = torch.arange(0, 3) # [0, 1, 2]\n",
    "t10 = torch.arange(3, 6) # [3, 4, 5]\n",
    "print(t9.size(), t10.size()) # 각각의 크기: 3\n",
    "\n",
    "t11 = torch.stack((t9, t10), dim=0) # 첫 번째 차원을 따라 벡터 쌓기 (2, 3)\n",
    "print(t11.size())\n",
    "print(t11)\n",
    "# [[0, 1, 2],\n",
    "# [3, 4, 5]]\n",
    "\n",
    "t12 = torch.cat((t9.unsqueeze(0), t10.unsqueeze(0)), dim=0) # 각 벡터에 첫 번째 차원을 추가하고 결합하기\n",
    "print(t11.equal(t12))\n",
    "# [[0, 1, 2],\n",
    "# [3, 4, 5]]\n",
    "\n",
    "t13 = torch.stack((t9, t10), dim=1)  # 두 번째 차원을 따라 벡터 쌓기 (3, 2)\n",
    "print(t13.size())\n",
    "# [[0, 3],\n",
    "# [1, 4],\n",
    "# [2, 5]]\n",
    "\n",
    "t14 = torch.cat((t9.unsqueeze(1), t10.unsqueeze(1)), dim=1) # 각 벡터에 두 번째 차원을 추가하고 결합하기\n",
    "print(t13.equal(t14))\n",
    "# [[0, 3],\n",
    "# [1, 4],\n",
    "# [2, 5]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f2be72-b892-4c5f-a331-058eb4687033",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "텐서를 결합하는 방식\n",
    "\n",
    "- **torch.stack()**\n",
    "    - 지정한 차원을 기준으로 새로운 차원을 추가하면서 텐서를 쌓는다.\n",
    "\n",
    "- **torch.cat()**\n",
    "     - 기존의 차원에서 텐서를 결합한다.\n",
    "     - unsqeeze()를 사용해서 차원을 추가할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db4147-2bbf-468b-ae76-cf44252b8c63",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "## **n_tensor_vstack_hstack**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f7fd4ce-cbcb-4004-97a3-b8c2574c8c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n"
     ]
    }
   ],
   "source": [
    "# 수직 스택\n",
    "t1 = torch.tensor([1, 2, 3])\n",
    "t2 = torch.tensor([4, 5, 6])\n",
    "t3 = torch.vstack((t1, t2)) # 두 벡터를 수직으로 쌓기\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6ab5657-5cf0-4c41-aabb-a1fce4330d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "t4 = torch.tensor([[1], [2], [3]]) # (3, 1)\n",
    "t5 = torch.tensor([[4], [5], [6]]) # (3, 1)\n",
    "t6 = torch.vstack((t4, t5)) # 두 벡터를 수직으로 쌓기 (3+3, 1)\n",
    "print(t6.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c382fc3a-b6a4-45c7-a4e6-38d8aae2afee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([4, 2, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]],\n",
      "\n",
      "        [[13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "t7 = torch.tensor([ # (2, 2, 3)\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t7.shape)\n",
    "\n",
    "t8 = torch.tensor([ # (2, 2, 3)\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t8.shape)\n",
    "\n",
    "t9 = torch.vstack([t7, t8]) # (4, 2, 3)\n",
    "print(t9.shape) \n",
    "print(t9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "32792c32-b82c-4089-b416-08e642dffe6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "# 수평 스택\n",
    "t10 = torch.tensor([1, 2, 3])\n",
    "t11 = torch.tensor([4, 5, 6])\n",
    "t12 = torch.hstack((t10, t11)) # 두 벡터를 수평으로 결합하기\n",
    "print(t12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3e75b9f0-b366-426e-b6bb-fbbc1ac1d692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n"
     ]
    }
   ],
   "source": [
    "t13 = torch.tensor([[1], [2], [3]])\n",
    "t14 = torch.tensor([[4], [5], [6]])\n",
    "t15 = torch.hstack((t13, t14)) # 두 벡터를 수평으로 결합하기\n",
    "print(t15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "90fbcbbf-fd77-4743-8dfb-d1fcc6e9499d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 2, 3])\n",
      "torch.Size([2, 4, 3])\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 4,  5,  6],\n",
      "         [13, 14, 15],\n",
      "         [16, 17, 18]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12],\n",
      "         [19, 20, 21],\n",
      "         [22, 23, 24]]])\n"
     ]
    }
   ],
   "source": [
    "t16 = torch.tensor([ # (2, 2, 3)\n",
    "  [[1, 2, 3], [4, 5, 6]],\n",
    "  [[7, 8, 9], [10, 11, 12]]\n",
    "])\n",
    "print(t16.shape)\n",
    "\n",
    "t17 = torch.tensor([ # (2, 2, 3)\n",
    "  [[13, 14, 15], [16, 17, 18]],\n",
    "  [[19, 20, 21], [22, 23, 24]]\n",
    "])\n",
    "print(t17.shape)\n",
    "\n",
    "t18 = torch.hstack([t16, t17]) # 두 벡터를 수평으로 결합하기 (2, 4, 3)\n",
    "print(t18.shape)  \n",
    "print(t18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a3a4d2-475d-4e0d-bbf5-59f0c7b88a6e",
   "metadata": {},
   "source": [
    "---\n",
    "**🔎기술적 사항/고찰 내용**\n",
    "\n",
    "수직 스택\n",
    "\n",
    "- **torch.vstack()**\n",
    "  \n",
    "  - 지정된 두 벡터를 첫 번째 차원을 기준으로 수직으로 결합한다.\n",
    "  - 행을 추가하는 방식이다.\n",
    "\n",
    "수평 스택\n",
    "\n",
    "- **torch.hstack()**\n",
    "  \n",
    "  - 지정된 두 벡터를 두 번째 차원을 기준으로 수평으로 결합한다.\n",
    "  - 열을 추가하는 방식이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953856fa-49bb-4ae2-be10-ee9ae2dc3463",
   "metadata": {},
   "source": [
    "<br/><br/>\n",
    "\n",
    "## **📌숙제 후기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21aa91f-102d-4a31-aeaf-2146cc71f731",
   "metadata": {},
   "source": [
    "hw1-1\n",
    "---\n",
    "\n",
    "처음에는 딥러닝에 대한 이론 수업을 들었지만 개념들이 워낙 방대하고 생소해서 그리 쉽게 와닿지는 않았다.\n",
    "하지만 이번 첫 번째 과제를 통해 직접 코드를 작성하고 실행해보면서 이론으로만 알고 있던 개념들이 조금씩 구체적으로 다가왔다. \n",
    "이번 과제는 생각했던 것보다 분량이 꽤 많아서 시간을 꽤 많이 투자해야 했다. 그럼에도 불구하고 내용 자체는 복잡하지 않았기 때문에 a부터 n까지 하나하나 단계를 완성해 나가면서 큰 어려움 없이 진행할 수 있었다. 특히 문제를 해결할 때마다 단계별로 성과가 보이는 것이 굉장히 뿌듯했고, 이를 통해 딥러닝의 기초적인 개념들을 자연스럽게 익혀나갈 수 있었다. 과제의 분량이 많았던 만큼 시간 관리가 부족했던 점도 아쉬웠다. 다음에는 좀 더 계획적으로 시간을 관리해서 여유 있게 공부하고 싶다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967f8b8c-edee-4a37-8a6f-6bf737ecf7b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
